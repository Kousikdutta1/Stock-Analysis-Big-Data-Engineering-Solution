{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6a78ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, IntegerType, StructType, StringType,FloatType,DateType\n",
    "from pyspark.sql.functions import lit,max,mean,min, first,desc,col,format_number\n",
    "\n",
    "# Declaring Path and Variables\n",
    "\n",
    "# driver = \"ODBC Driver 18 for SQL Server\"\n",
    "driver = \"SQL Server\"\n",
    "server = \"DESKTOP-TOEPTEF\\SQL_SERVER\"\n",
    "port = 1433\n",
    "\n",
    "# table Name\n",
    "table_name = \"walmart_stock\"\n",
    "\n",
    "# databse_name\n",
    "db_name='walmart_stock_analysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347935e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a connection string\n",
    "\n",
    "conn_url = f'DRIVER={driver};Server={server};Port={port}'\n",
    "conn = pyodbc.connect(conn_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5f5e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa966af",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_db = f\"use {db_name}\"\n",
    "curs.execute(use_db)\n",
    "curs.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3f30c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "curs.execute(\n",
    "\"\"\"select\n",
    "* from \n",
    "walmart_stock\n",
    "\"\"\")\n",
    "\n",
    "query_results = curs.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2fc6ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2012-01-03', 59.970001220703125, 61.060001373291016, 59.869998931884766, 60.33000183105469, 12668800, 52.61923599243164),\n",
       " ('2012-01-04', 60.209999084472656, 60.349998474121094, 59.470001220703125, 59.709999084472656, 9593300, 52.07847595214844),\n",
       " ('2012-01-05', 59.349998474121094, 59.619998931884766, 58.369998931884766, 59.41999816894531, 12768200, 51.825538635253906)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check top 3\n",
    "\n",
    "query_results[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "135fc6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curs.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce3e45",
   "metadata": {},
   "source": [
    "**-- PySpark --**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de14cf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-TOEPTEF:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now create spark context\n",
    "\n",
    "sc = pyspark.SparkContext()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3717252",
   "metadata": {},
   "outputs": [],
   "source": [
    "walmartrdd = sc.parallelize(query_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bcc0d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2012-01-03', 59.970001220703125, 61.060001373291016, 59.869998931884766, 60.33000183105469, 12668800, 52.61923599243164),\n",
       " ('2012-01-04', 60.209999084472656, 60.349998474121094, 59.470001220703125, 59.709999084472656, 9593300, 52.07847595214844)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see the data.\n",
    "\n",
    "walmartrdd.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d99a0a",
   "metadata": {},
   "source": [
    "**-- RDD --**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c968e6",
   "metadata": {},
   "source": [
    "### **Scenario 7: How many days was the Close lower than 60 dollars?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a77e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "walmartrdd2 = walmartrdd.map(lambda line:(line[0],int(line[4])))\\\n",
    ".filter(lambda item:float(item[1]) < 60)\\\n",
    ".map(lambda x: (x[0],1))\\\n",
    ".count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72e68e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 days was the close lower than 60 dollars.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{walmartrdd2} days was the close lower than 60 dollars.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b2a48",
   "metadata": {},
   "source": [
    "### Scenario 8: What percentage of the time was the High greater than 80 dollars ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "401fc328",
   "metadata": {},
   "outputs": [],
   "source": [
    "walmartrdd3 = (walmartrdd.map(lambda line:(line[0],int(line[2])))\\\n",
    ".filter(lambda item:float(item[1]) > 80)\\\n",
    ".map(lambda x: (x[0],1))\\\n",
    ".count())/walmartrdd.count()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23e6f402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.43 % of the time was the high greater than 80 dollars.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{round(walmartrdd3, 2)} % of the time was the high greater than 80 dollars.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e88475",
   "metadata": {},
   "source": [
    "### Scenario 9: What is the max High per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a6e0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "walmartrdd4 = walmartrdd.map(lambda x: (int(x[0].split('-')[0]), x[2]))\\\n",
    ".reduceByKey(lambda a, b: round(a,2) if a>b else round(b,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "659b61d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max High Per Year: [(2016, 75.19), (2012, 77.6), (2013, 81.37), (2014, 88.09), (2015, 90.97)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Max High Per Year: %s\"%walmartrdd4.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d1a19",
   "metadata": {},
   "source": [
    "**-- DSL & SparkSQL --**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c964f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SparkSession.builder.appName(\"project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3cc2493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-TOEPTEF:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x29989695e40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10187c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define schema\n",
    "\n",
    "data_schema = [StructField('Date',DateType(),True),\n",
    "               StructField('Open',FloatType(),True),\n",
    "               StructField('High',FloatType(),True),\n",
    "               StructField('Low',FloatType(),True),\n",
    "               StructField('Close',FloatType(),True),\n",
    "              StructField('Volume',IntegerType(),True),\n",
    "              StructField('Adj Close',FloatType(),True),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a892e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create a structtype with the schema as field\n",
    "\n",
    "df_schema = StructType(fields = data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b095b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ss.read.csv(r'C:\\Users\\Futurense\\Desktop\\Walmart Project DE\\Project documents\\HIVE WALMART STOCK\\walmart_stock.csv', schema = df_schema, header =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36fdb721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+--------+---------+\n",
      "|      Date| Open| High|  Low|Close|  Volume|Adj Close|\n",
      "+----------+-----+-----+-----+-----+--------+---------+\n",
      "|2012-01-03|59.97|61.06|59.87|60.33|12668800|52.619236|\n",
      "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|52.078476|\n",
      "|2012-01-05|59.35|59.62|58.37|59.42|12768200| 51.82554|\n",
      "|2012-01-06|59.42|59.45|58.87| 59.0| 8069400| 51.45922|\n",
      "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|51.616215|\n",
      "|2012-01-10|59.43|59.71|58.98|59.04| 6907300| 51.49411|\n",
      "|2012-01-11|59.06|59.53|59.04| 59.4| 6365600|51.808098|\n",
      "|2012-01-12|59.79| 60.0| 59.4| 59.5| 7236400|51.895317|\n",
      "|2012-01-13|59.18|59.61|59.01|59.54| 7729300|51.930202|\n",
      "|2012-01-17|59.87|60.11|59.52|59.85| 8500000| 52.20058|\n",
      "|2012-01-18|59.79|60.03|59.65|60.01| 5911400| 52.34013|\n",
      "|2012-01-19|59.93|60.73|59.75|60.61| 9234600|52.863445|\n",
      "|2012-01-20|60.75|61.25|60.67|61.01|10378800|53.212322|\n",
      "|2012-01-23|60.81|60.98|60.51|60.91| 7134100|53.125103|\n",
      "|2012-01-24|60.75| 62.0|60.75|61.39| 7362800|53.543755|\n",
      "|2012-01-25|61.18|61.61|61.04|61.47| 5915800| 53.61353|\n",
      "|2012-01-26| 61.8|61.84|60.77|60.97| 7436200|53.177437|\n",
      "|2012-01-27|60.86|61.12|60.54|60.71| 6287300|52.950665|\n",
      "|2012-01-30|60.47|61.32|60.35| 61.3| 7636900|53.465256|\n",
      "|2012-01-31|61.53|61.57|60.58|61.36| 9761500| 53.51759|\n",
      "+----------+-----+-----+-----+-----+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f12dc508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create view for doing spark-sql programm \n",
    "\n",
    "df.createOrReplaceTempView(\"walmartstock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24529998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: float (nullable = true)\n",
      " |-- High: float (nullable = true)\n",
      " |-- Low: float (nullable = true)\n",
      " |-- Close: float (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's do the printschema\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d04a47",
   "metadata": {},
   "source": [
    "#### Scenario 2:There are too many decimal places for mean and stddev in the describe() dataframe. Format the numbers to just show up to two decimal places. Pay careful attention to the datatypes that .describe() returns, we didn't cover how to do this exact formatting, but we covered something very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a461fe7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|             Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|             1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean|72.35785375452572| 72.8393880756178|71.91860094964979|72.38844997363553|8222093.481717011|67.23883840200064|\n",
      "| stddev|6.768090251767697|6.768186825250206|6.744075739203606|6.756859160119612|  4519780.8431556|6.722609385249684|\n",
      "|    min|            56.39|            57.06|             56.3|            56.42|          2094900|         50.36369|\n",
      "|    max|             90.8|            90.97|            89.25|            90.47|         80898100|        84.914215|\n",
      "+-------+-----------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c38f0eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+-------------+---------+\n",
      "|summary|    Open|    High|     Low|   Close|       Volume|Adj Close|\n",
      "+-------+--------+--------+--------+--------+-------------+---------+\n",
      "|  count|1,258.00|1,258.00|1,258.00|1,258.00|     1,258.00| 1,258.00|\n",
      "|   mean|   72.36|   72.84|   71.92|   72.39| 8,222,093.50|    67.24|\n",
      "| stddev|    6.77|    6.77|    6.74|    6.76| 4,519,781.00|     6.72|\n",
      "|    min|   56.39|   57.06|   56.30|   56.42| 2,094,900.00|    50.36|\n",
      "|    max|   90.80|   90.97|   89.25|   90.47|80,898,096.00|    84.91|\n",
      "+-------+--------+--------+--------+--------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().withColumn(\"Open\", format_number(col(\"Open\").cast('float'),2))\\\n",
    ".withColumn(\"High\", format_number(col(\"High\").cast('float'),2))\\\n",
    ".withColumn(\"Low\", format_number(col(\"Low\").cast('float'),2))\\\n",
    ".withColumn(\"Close\", format_number(col(\"Close\").cast('float'),2))\\\n",
    ".withColumn(\"Volume\", format_number(col(\"Volume\").cast('float'),2))\\\n",
    ".withColumn(\"Adj Close\", format_number(col(\"Adj Close\").cast('float'),2))\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce247807",
   "metadata": {},
   "source": [
    "#### Scenario 3: Create a new dataframe with a column called VH Ratio that is the ratio of the Volume Price VS High of stock traded for a day.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "173fdf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+--------+---------+---------+\n",
      "|      Date| Open| High|  Low|Close|  Volume|Adj Close| HV_Ratio|\n",
      "+----------+-----+-----+-----+-----+--------+---------+---------+\n",
      "|2012-01-03|59.97|61.06|59.87|60.33|12668800|52.619236|207481.16|\n",
      "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|52.078476|158961.06|\n",
      "|2012-01-05|59.35|59.62|58.37|59.42|12768200| 51.82554|214159.68|\n",
      "|2012-01-06|59.42|59.45|58.87| 59.0| 8069400| 51.45922|135734.23|\n",
      "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|51.616215|112162.89|\n",
      "|2012-01-10|59.43|59.71|58.98|59.04| 6907300| 51.49411|115680.79|\n",
      "|2012-01-11|59.06|59.53|59.04| 59.4| 6365600|51.808098|106930.96|\n",
      "|2012-01-12|59.79| 60.0| 59.4| 59.5| 7236400|51.895317|120606.67|\n",
      "|2012-01-13|59.18|59.61|59.01|59.54| 7729300|51.930202|129664.48|\n",
      "|2012-01-17|59.87|60.11|59.52|59.85| 8500000| 52.20058|141407.42|\n",
      "|2012-01-18|59.79|60.03|59.65|60.01| 5911400| 52.34013|  98474.1|\n",
      "|2012-01-19|59.93|60.73|59.75|60.61| 9234600|52.863445|152059.94|\n",
      "|2012-01-20|60.75|61.25|60.67|61.01|10378800|53.212322| 169449.8|\n",
      "|2012-01-23|60.81|60.98|60.51|60.91| 7134100|53.125103|116990.82|\n",
      "|2012-01-24|60.75| 62.0|60.75|61.39| 7362800|53.543755|118754.84|\n",
      "|2012-01-25|61.18|61.61|61.04|61.47| 5915800| 53.61353| 96020.13|\n",
      "|2012-01-26| 61.8|61.84|60.77|60.97| 7436200|53.177437|120249.03|\n",
      "|2012-01-27|60.86|61.12|60.54|60.71| 6287300|52.950665|102868.13|\n",
      "|2012-01-30|60.47|61.32|60.35| 61.3| 7636900|53.465256|124541.75|\n",
      "|2012-01-31|61.53|61.57|60.58|61.36| 9761500| 53.51759|158543.12|\n",
      "+----------+-----+-----+-----+-----+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark - SQL Technique\n",
    "\n",
    "ss.sql(\"select *, round(cast(Volume as float)/cast(High as float),2) as HV_Ratio from walmartstock\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65791721",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+--------+---------+---------+\n",
      "|      Date| Open| High|  Low|Close|  Volume|Adj Close| HV Ratio|\n",
      "+----------+-----+-----+-----+-----+--------+---------+---------+\n",
      "|2012-01-03|59.97|61.06|59.87|60.33|12668800|52.619236|207481.16|\n",
      "|2012-01-04|60.21|60.35|59.47|59.71| 9593300|52.078476|158961.06|\n",
      "|2012-01-05|59.35|59.62|58.37|59.42|12768200| 51.82554|214159.68|\n",
      "|2012-01-06|59.42|59.45|58.87| 59.0| 8069400| 51.45922|135734.23|\n",
      "|2012-01-09|59.03|59.55|58.92|59.18| 6679300|51.616215|112162.89|\n",
      "|2012-01-10|59.43|59.71|58.98|59.04| 6907300| 51.49411|115680.79|\n",
      "|2012-01-11|59.06|59.53|59.04| 59.4| 6365600|51.808098|106930.96|\n",
      "|2012-01-12|59.79| 60.0| 59.4| 59.5| 7236400|51.895317|120606.67|\n",
      "|2012-01-13|59.18|59.61|59.01|59.54| 7729300|51.930202|129664.48|\n",
      "|2012-01-17|59.87|60.11|59.52|59.85| 8500000| 52.20058|141407.42|\n",
      "|2012-01-18|59.79|60.03|59.65|60.01| 5911400| 52.34013|  98474.1|\n",
      "|2012-01-19|59.93|60.73|59.75|60.61| 9234600|52.863445|152059.94|\n",
      "|2012-01-20|60.75|61.25|60.67|61.01|10378800|53.212322| 169449.8|\n",
      "|2012-01-23|60.81|60.98|60.51|60.91| 7134100|53.125103|116990.82|\n",
      "|2012-01-24|60.75| 62.0|60.75|61.39| 7362800|53.543755|118754.84|\n",
      "|2012-01-25|61.18|61.61|61.04|61.47| 5915800| 53.61353| 96020.13|\n",
      "|2012-01-26| 61.8|61.84|60.77|60.97| 7436200|53.177437|120249.03|\n",
      "|2012-01-27|60.86|61.12|60.54|60.71| 6287300|52.950665|102868.13|\n",
      "|2012-01-30|60.47|61.32|60.35| 61.3| 7636900|53.465256|124541.75|\n",
      "|2012-01-31|61.53|61.57|60.58|61.36| 9761500| 53.51759|158543.12|\n",
      "+----------+-----+-----+-----+-----+--------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DSL Technique\n",
    "\n",
    "df.withColumn('HV Ratio',round(lit(col('Volume').cast('float')/col('High').cast('float')),2)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b851b1",
   "metadata": {},
   "source": [
    "#### Scenario 4: What day had the Peak High in Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3485cb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      Date| High|\n",
      "+----------+-----+\n",
      "|2015-01-13|90.97|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark-SQL techinique\n",
    "\n",
    "ss.sql(\"select Date, High from walmartstock order by High desc limit 1\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3776e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      Date| High|\n",
      "+----------+-----+\n",
      "|2015-01-13|90.97|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DSL\n",
    "\n",
    "df.orderBy(desc('High')).select(\"Date\", \"High\").limit(1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a9dfd",
   "metadata": {},
   "source": [
    "#### Scenario 5: What is the mean of the Close column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67b633fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55c09adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|mean_close|\n",
      "+----------+\n",
      "|     72.39|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark - SQL Technique\n",
    "\n",
    "ss.sql(\"select round(avg(Close),2) as mean_close from walmartstock\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01e98c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Mean_Close|\n",
      "+----------+\n",
      "|     72.39|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DSL Technique\n",
    "\n",
    "df.select(round(mean(df.Close),2).alias(\"Mean_Close\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7b9e5",
   "metadata": {},
   "source": [
    "#### Scenario 6: What is the max and min of the Volume column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "748ffce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|max_volume|min_volume|\n",
      "+----------+----------+\n",
      "|  80898100|   2094900|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Spark - Sql Technique\n",
    "\n",
    "ss.sql(\"select round(max(Volume)) as max_volume, round(min(Volume)) as min_volume from walmartstock\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f464262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|Max_Volume|Min_Volume|\n",
      "+----------+----------+\n",
      "|  80898100|   2094900|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DSL Technique\n",
    "\n",
    "df.select(round(max(df.Volume),2).alias(\"Max_Volume\"), round(min(df.Volume),2).alias(\"Min_Volume\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
